= Showcase for Hadoop with CDC on Quarkus

This project holds a showcase for Hadoop with CDC on Quarkus.

== Instructions

Following make targets exist in the subfolder podman:

- **pd-machine-create** - Create a suitable Qemu machine
- **pd-pod-create** - Create the pod with port mappings
- **pd-build** - Build all images
- **pd-start** - Start all container

== Problems

=== Dockerfile

Apparently, the datanodes use components like C-libraries which I couldn't get NOT to dump core
dump with Alpine/Musl.

=== Podman

Starting with Podman 4.4.1 they dropped the default privileges for chroot, which led to following
problems on connection:

```
ssh: Connection closed by 127.0.0.1 port 22
sshd: chroot("/run/sshd"): Operation not permitted [preauth]
```

- https://github.com/containers/podman/releases/tag/v4.4.1
- https://forum.gitlab.com/t/failure-on-ssh-push-pull/82244

=== Scala

```text
java.lang.NoSuchMethodError: 'scala.collection.immutable.ArraySeq scala.runtime.ScalaRunTime$.wrapRefArray(java.lang.Object[])'
```

```text
Caused by: java.lang.ClassNotFoundException: scala.$less$colon$less
```

Make sure the Scala version of the jars/dependencies match the Scala version of Spark.

This can be easily checked with:

```shell
mvn dependency:tree
```

== Hive

The jdbc connection string for either anonymous or *hduser* for Hive is following:

[source,txt]
----
jdbc:hive2://localhost:10000/default
----

And adding the external Debezium table works:

[source,sql]
----
add jar /home/hduser/hive/lib/iceberg-hive-runtime-1.1.0.jar;
create external table debezium stored by 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' location 'hdfs://localhost:9000/warehouse/debeziumevents/debeziumcdc_showcase_public_todos' TBLPROPERTIES ('iceberg.catalog'='location_based_table')"
----

== Links

=== Hadoop

- https://medium.com/analytics-vidhya/hadoop-single-node-cluster-on-docker-e88c3d09a256
- https://github.com/rancavil/hadoop-single-node-cluster
- https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html
- https://www.edureka.co/blog/install-hadoop-single-node-hadoop-cluster
- https://stackoverflow.com/questions/41266403/how-to-access-hadoop-web-ui-in-linux
- https://www.digitalocean.com/community/tutorials/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-20-04
- https://www.ibm.com/docs/el/db2-big-sql/5.0?topic=applications-impersonation-in-big-sql

==== Config defaults

- https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
- https://hadoop.apache.org/docs/r2.7.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml

=== Debezium

- https://hub.docker.com/r/debezium/server
- https://debezium.io/documentation/reference/stable/operations/debezium-server.html
- https://github.com/memiiso/debezium-server-iceberg
- https://debezium.io/blog/2021/10/20/using-debezium-create-data-lake-with-apache-iceberg/
- https://iceberg.apache.org/
- https://hadoop.apache.org/docs/r1.0.4/webhdfs.html#FsURIvsHTTP_URL
- https://stackoverflow.com/questions/59978213/debezium-could-not-access-file-decoderbufs-using-postgres-11-with-default-plug
- https://debezium.io/documentation/reference/stable/development/engine.html#database-history-properties

=== Iceberg

- https://iceberg.apache.org/docs/latest/hive/#create-external-table-overlaying-an-existing-iceberg-table
- https://iceberg.apache.org/releases/#downloads

=== Spark

- https://www.dremio.com/blog/introduction-to-apache-iceberg-using-spark/
- https://spark.apache.org/docs/latest/sql-getting-started.html
- https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html
- https://sparkbyexamples.com/apache-hive/how-to-connect-spark-to-remote-hive/
- https://codait.github.io/spark-bench/

=== Scala

- https://davidb.github.io/scala-maven-plugin/usage.html
- https://www.alibabacloud.com/help/en/e-mapreduce/latest/use-spark-to-write-data-to-an-iceberg-table-in-streaming-mode
